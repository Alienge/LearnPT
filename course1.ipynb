{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看pytorch的版本，加载一些常用的函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy到torch tensor的转换，验证一个对象是否是torch tensor的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([1,2.,3])\n",
    "torch_array = torch.from_numpy(array)\n",
    "print(torch_array)\n",
    "print(torch_array.numpy())\n",
    "print(torch.is_tensor(array))\n",
    "print(torch.is_tensor(torch_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch storage的用法，torch tensor到torch storage的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Storage是单一数据类型的一维数组\n",
    "torch_array = torch.tensor([1,2,3,4])\n",
    "array = np.array([1.,2,3,4,5])\n",
    "torch_storage = torch.FloatStorage(array)\n",
    "print(torch_storage)\n",
    "# 转换数据类型\n",
    "print(torch_storage.int().type())\n",
    "# clone\n",
    "print(torch_storage.clone())\n",
    "print(torch_storage.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判断torch是否是浮点型的数据, 并且设置默认类型的时候只支持float类型的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_tensor = torch.tensor([[1.,2,3],[4,5,6]])\n",
    "print(array_tensor)\n",
    "# this function is testing the type of tensor\n",
    "print(torch.is_floating_point(array_tensor))\n",
    "print(array_tensor.dtype)\n",
    "print(torch.set_default_dtype(torch.float16))\n",
    "array_tensor = torch.tensor([[1.,2,3],[4,5,6]])\n",
    "print(array_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch中计算tensor中元素的总个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float16)\n",
    "a = torch.randn(1,2,3,4,5)\n",
    "print(a)\n",
    "torch.numel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch[cpuType]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros(2,2)\n",
    "torch.numel(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 不太明白这里面的参数含义(应该是输出时，显示格式的修改)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensor读数据的时候都是浅拷贝，为避免拷贝，使用其他torch.Tensor.required_grad或者torch.Tensor.detach,如果输入的数据类型为numpy的形式，使用torch.as_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.Tensor.detach(a)\n",
    "c = np.array([[1,2,3],[4,5,6]])\n",
    "d = torch.as_tensor(c)\n",
    "e = torch.tensor([1,2,3,4,5],dtype=torch.float32,device=torch.device('cuda:0'))\n",
    "print(a)\n",
    "print(b)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.get_device_properties(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.sparse_coo_tensor, 构建稀疏张量，i前面的是延x与y方向上的元素索引值，v后面对应的是函数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.tensor([[0,1,1],[2,0,2]])\n",
    "v = torch.tensor([3,4,5], dtype=torch.float32)\n",
    "d = torch.sparse_coo_tensor(i,v,[2,4]).to_dense()\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.sparse.FloatTensor(2,3).to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "print(torch.empty([1,0]))\n",
    "torch.sparse_coo_tensor(torch.empty([1,0]),torch.empty([0,2]),[1,2]).to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在cpu中，torch.as_tensor中复制array的是地址，而在gpu中和正常的复制类似，不共享地址，是单独复制一份出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "b = torch.as_tensor(a)\n",
    "print(b)\n",
    "b[1][0]=100\n",
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([11,12,13])\n",
    "d = torch.as_tensor(c,device=torch.device(\"cuda\"))\n",
    "print(d)\n",
    "d[2] = 1000\n",
    "print(d)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.as_strided() 将元素进行类似的切片操作，第一个参数是生成结果的size，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.as_strided(x,(2,2),(1,2))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([1,2,3])\n",
    "numpy_t = torch.from_numpy(t)\n",
    "numpy_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化torch的一些函数, empty中是未初始化的值，意思是随机的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros1 = torch.zeros((2,2))\n",
    "zeros2 = torch.zeros_like(numpy_t)\n",
    "empty1 = torch.empty((2,3))\n",
    "print(zeros1)\n",
    "print(zeros2)\n",
    "print(empty1)\n",
    "one1 = torch.ones(2,2)\n",
    "one2 = torch.ones_like(numpy_t)\n",
    "print(one1)\n",
    "print(one2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(0,10,2)\n",
    "print(a)\n",
    "b = torch.range(0,5)\n",
    "print(b)\n",
    "c = torch.linspace(0,10,20)\n",
    "print(c)\n",
    "d = torch.logspace(0,10,3)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.eye(2,3)\n",
    "d = torch.\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 填充数据和缩放和偏移数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1416, 3.1416, 3.1416],\n",
      "        [3.1416, 3.1416, 3.1416]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.full((2,3),3.1415926)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1234567., 1234567., 1234567.],\n",
      "        [1234567., 1234567., 1234567.]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.full_like(a,1234567)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'quantize_per_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b81045cbc4c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantize_per_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'quantize_per_tensor'"
     ]
    }
   ],
   "source": [
    "#b = torch.quantize_per_tensor(torch.tensor([-1.0,0.0,1.0,2.0]),0.1,10,torch.quint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 索引，连接，和相乘等操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1639,  0.6393, -0.3455],\n",
      "        [ 0.8460, -0.7322,  1.3227]])\n",
      "tensor([[ 1.1639,  0.6393, -0.3455,  1.1639,  0.6393, -0.3455,  1.1639,  0.6393,\n",
      "         -0.3455],\n",
      "        [ 0.8460, -0.7322,  1.3227,  0.8460, -0.7322,  1.3227,  0.8460, -0.7322,\n",
      "          1.3227]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "print(x)\n",
    "#y = torch.cat((x,x,x),0)\n",
    "y = torch.cat((x,x,x),1) \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1],\n",
      "        [4]]), tensor([[2],\n",
      "        [5]]), tensor([[3],\n",
      "        [6]]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.chunk(torch.tensor([[1,2,3],[4,5,6]]),3,dim=1)#操作的维度不变\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据索引选取对应的值"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
